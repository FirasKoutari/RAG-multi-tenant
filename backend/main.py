from __future__ import annotations

import os
import time
from datetime import datetime
from fastapi import FastAPI, Header, HTTPException, Depends, UploadFile, File
from pydantic import BaseModel, Field
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session

from .tenants import resolve_tenant
from .search import MultiTenantSearch, build_llm_answer
from .database import get_db, init_db
from .models import QueryLog, APIKeyUsage, TenantDocument


APP_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(APP_DIR, "data")  

search_engine = MultiTenantSearch(base_dir=DATA_DIR)
# Preload the two tenants (optional, but nice for faster first request)
search_engine.load_tenant("tenantA")
search_engine.load_tenant("tenantB")

app = FastAPI(title="Multi-tenant SaaS Search API", version="2.0.0")

# √âv√©nement de d√©marrage: initialiser la base de donn√©es
@app.on_event("startup")
async def startup_event():
    """Initialise la base de donn√©es au d√©marrage de l'application."""
    init_db()
    print("‚úÖ Application d√©marr√©e avec BDD SQLite et LLM Ollama")

# For Streamlit local dev
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

class QueryRequest(BaseModel):
    # üîí S√âCURIT√â CRITIQUE: Le tenant_id n'est JAMAIS dans le body
    # La s√©paration des clients doit √™tre transparente pour l'utilisateur
    # et g√©r√©e uniquement c√¥t√© serveur via le header X-API-KEY
    question: str = Field(..., min_length=1, max_length=2000)

class Source(BaseModel):
    doc_id: str
    chunk_id: int
    score: float
    excerpt: str

class QueryResponse(BaseModel):
    tenant_id: str
    answer: str | None
    sources: list[Source]
    no_answer: bool
    llm_used: bool = False  # Indique si le LLM a √©t√© utilis√©

def get_tenant_or_401(x_api_key: str | None) -> str:
    """R√©sout l'identit√© du tenant via X-API-KEY.
    
    üîí S√âCURIT√â: Point d'entr√©e critique de l'isolation multi-tenant.
    Si la cl√© est invalide/manquante ‚Üí 401 (pas d'acc√®s).
    
    Cette fonction est appel√©e sur CHAQUE requ√™te pour garantir que
    le backend ne traite que les donn√©es du tenant authentifi√©.
    """
    tenant = resolve_tenant(x_api_key)
    if tenant is None:
        raise HTTPException(status_code=401, detail="Invalid or missing X-API-KEY")
    return tenant.id

@app.get("/health")
def health():
    """Endpoint de sant√© avec informations sur les services."""
    from .services.llm import llm_service
    
    return {
        "status": "ok",
        "database": "sqlite",
        "llm": {
            "available": llm_service.is_available(),
            "model": llm_service.model
        }
    }

@app.get("/stats/{tenant_id}")
def get_tenant_stats(
    tenant_id: str,
    x_api_key: str | None = Header(default=None, alias="X-API-KEY"),
    db: Session = Depends(get_db)
):
    """R√©cup√®re les statistiques d'utilisation d'un tenant.
    
    N√©cessite une authentification via X-API-KEY du tenant concern√©.
    """
    # V√©rifier que l'API key correspond au tenant demand√©
    authenticated_tenant = get_tenant_or_401(x_api_key)
    if authenticated_tenant != tenant_id:
        raise HTTPException(status_code=403, detail="Access denied to this tenant's stats")
    
    # R√©cup√©rer les statistiques
    total_queries = db.query(QueryLog).filter(QueryLog.tenant_id == tenant_id).count()
    llm_queries = db.query(QueryLog).filter(
        QueryLog.tenant_id == tenant_id,
        QueryLog.query_metadata.contains('"llm_used": true')
    ).count()
    no_answer_queries = db.query(QueryLog).filter(
        QueryLog.tenant_id == tenant_id,
        QueryLog.no_answer == True
    ).count()
    
    # R√©cup√©rer les derni√®res requ√™tes
    recent_queries = db.query(QueryLog).filter(
        QueryLog.tenant_id == tenant_id
    ).order_by(QueryLog.created_at.desc()).limit(10).all()
    
    return {
        "tenant_id": tenant_id,
        "total_queries": total_queries,
        "llm_queries": llm_queries,
        "extractive_queries": total_queries - llm_queries,
        "no_answer_queries": no_answer_queries,
        "recent_queries": [
            {
                "id": q.id,
                "question": q.question[:100],  # Tronquer pour s√©curit√©
                "no_answer": q.no_answer,
                "sources_count": q.sources_count,
                "execution_time_ms": q.execution_time_ms,
                "created_at": q.created_at.isoformat()
            }
            for q in recent_queries
        ]
    }

@app.post("/query", response_model=QueryResponse)
def query(
    req: QueryRequest, 
    x_api_key: str | None = Header(default=None, alias="X-API-KEY"),
    db: Session = Depends(get_db)
):
    """Endpoint de recherche multi-tenant s√©curis√© avec LLM et logging BDD.
    
    üîí FLUX DE S√âCURIT√â:
    1. R√©solution du tenant via X-API-KEY (401 si invalide)
    2. R√©cup√©ration de l'index isol√© du tenant
    3. Recherche UNIQUEMENT dans les documents de CE tenant
    4. G√©n√©ration de r√©ponse avec LLM (Ollama + Mistral)
    5. Logging de la requ√™te dans la base de donn√©es
    6. Retour avec sources tra√ßables (doc_id, chunk_id, score)
    
    ‚úÖ Garantie z√©ro fuite: Impossible d'acc√©der aux docs d'un autre tenant
    ‚úÖ Anti-hallucination: Prompt strict + seuil MIN_SCORE
    ü§ñ IA g√©n√©rative: LLM local Ollama/Mistral pour r√©ponses naturelles
    üìä Tra√ßabilit√©: Toutes les requ√™tes logg√©es en base
    """
    start_time = time.time()
    
    # üîë √âtape 1: Authentification et r√©solution du tenant
    tenant_id = get_tenant_or_401(x_api_key)
    
    # üìä Mise √† jour des statistiques d'utilisation de l'API Key
    api_usage = db.query(APIKeyUsage).filter(
        APIKeyUsage.tenant_id == tenant_id,
        APIKeyUsage.api_key == x_api_key
    ).first()
    
    if api_usage:
        api_usage.request_count += 1
        api_usage.last_used_at = datetime.now()
    else:
        api_usage = APIKeyUsage(
            tenant_id=tenant_id,
            api_key=x_api_key,
            request_count=1,
            last_used_at=datetime.now()
        )
        db.add(api_usage)
    
    db.commit()

    # üìö √âtape 2: Chargement de l'index isol√© du tenant
    idx = search_engine.get(tenant_id)
    hits = idx.search(req.question, top_k=3)

    # üõ°Ô∏è √âtape 3: Filtrage anti-hallucination (seuil de confiance)
    MIN_SCORE = 0.12
    hits = [h for h in hits if h.score >= MIN_SCORE]

    if not hits:
        # Pas de r√©sultats pertinents
        execution_time_ms = (time.time() - start_time) * 1000
        
        # Logging dans la base de donn√©es
        query_log = QueryLog(
            tenant_id=tenant_id,
            question=req.question,
            answer=None,
            no_answer=True,
            sources_count=0,
            execution_time_ms=execution_time_ms,
            query_metadata={"min_score": MIN_SCORE}
        )
        db.add(query_log)
        db.commit()
        
        return QueryResponse(
            tenant_id=tenant_id,
            answer=None,
            sources=[],
            no_answer=True,
            llm_used=False,
        )

    # ü§ñ √âtape 4: G√©n√©ration de r√©ponse avec LLM (Ollama + Mistral)
    answer, llm_used = build_llm_answer(hits, req.question)
    
    # üìä √âtape 5: Pr√©paration des sources
    sources = [
        Source(
            doc_id=h.chunk.doc_id,
            chunk_id=h.chunk.chunk_id,
            score=round(h.score, 4),
            excerpt=h.chunk.text,
        )
        for h in hits
    ]
    
    # Calcul du temps d'ex√©cution
    execution_time_ms = (time.time() - start_time) * 1000
    
    # üíæ √âtape 6: Logging dans la base de donn√©es
    query_log = QueryLog(
        tenant_id=tenant_id,
        question=req.question,
        answer=answer,
        no_answer=False,
        sources_count=len(sources),
        execution_time_ms=execution_time_ms,
        query_metadata={
            "llm_used": llm_used,
            "min_score": MIN_SCORE,
            "sources": [
                {
                    "doc_id": s.doc_id,
                    "chunk_id": s.chunk_id,
                    "score": s.score
                }
                for s in sources
            ]
        }
    )
    db.add(query_log)
    db.commit()
    
    return QueryResponse(
        tenant_id=tenant_id,
        answer=answer,
        sources=sources,
        no_answer=False,
        llm_used=llm_used,
    )


@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    x_api_key: str | None = Header(None, alias="X-API-KEY"),
    db: Session = Depends(get_db)
):
    """
    üì§ Upload d'un document .txt pour un tenant.
    
    Le fichier est:
    1. Sauvegard√© dans backend/data/{tenant_id}/{filename}
    2. Enregistr√© dans la table tenant_documents
    3. Automatiquement r√©index√© pour recherche s√©mantique
    
    Authentification: Header X-API-KEY requis
    Format accept√©: .txt uniquement
    """
    # üîê √âtape 1: Authentification
    tenant = resolve_tenant(x_api_key)
    if not tenant:
        raise HTTPException(status_code=401, detail="Invalid or missing X-API-KEY")
    
    tenant_id = tenant.id
    
    # üìÑ √âtape 2: Validation du fichier
    if not file.filename.endswith('.txt'):
        raise HTTPException(
            status_code=400,
            detail="Only .txt files are accepted"
        )
    
    # üìÅ √âtape 3: Cr√©ation du r√©pertoire tenant si n√©cessaire
    tenant_dir = os.path.join(DATA_DIR, tenant_id)
    os.makedirs(tenant_dir, exist_ok=True)
    
    # üíæ √âtape 4: Sauvegarde du fichier
    file_path = os.path.join(tenant_dir, file.filename)
    
    # Lire le contenu du fichier
    content = await file.read()
    
    # V√©rifier que le contenu n'est pas vide
    if not content or len(content.strip()) == 0:
        raise HTTPException(
            status_code=400,
            detail="File is empty"
        )
    
    # Sauvegarder le fichier
    with open(file_path, "wb") as f:
        f.write(content)
    
    # üóÑÔ∏è √âtape 5: Enregistrement dans la base de donn√©es
    # V√©rifier si le document existe d√©j√†
    existing_doc = db.query(TenantDocument).filter(
        TenantDocument.tenant_id == tenant_id,
        TenantDocument.doc_id == file.filename
    ).first()
    
    if existing_doc:
        # Mettre √† jour le document existant
        existing_doc.updated_at = datetime.utcnow()
        existing_doc.chunks_count = 0  # Sera recalcul√© lors de la r√©indexation
    else:
        # Cr√©er une nouvelle entr√©e
        new_doc = TenantDocument(
            tenant_id=tenant_id,
            doc_id=file.filename,
            doc_path=file_path,
            chunks_count=0,  # Sera calcul√© lors de la r√©indexation
            indexed_at=datetime.utcnow()
        )
        db.add(new_doc)
    
    db.commit()
    
    # üîÑ √âtape 6: R√©indexation du tenant
    try:
        search_engine.reload_tenant(tenant_id)
        
        # Calculer le nombre de chunks pour ce document
        chunks_count = 0
        tenant_index = search_engine.get_tenant_index(tenant_id)
        if tenant_index:
            chunks_count = sum(
                1 for chunk in tenant_index.chunks
                if chunk.doc_id == file.filename
            )
        
        # Mettre √† jour le nombre de chunks
        doc = db.query(TenantDocument).filter(
            TenantDocument.tenant_id == tenant_id,
            TenantDocument.doc_id == file.filename
        ).first()
        if doc:
            doc.chunks_count = chunks_count
            db.commit()
        
        return {
            "status": "success",
            "message": f"Document '{file.filename}' uploaded and indexed successfully",
            "tenant_id": tenant_id,
            "filename": file.filename,
            "chunks_count": chunks_count,
            "file_size_bytes": len(content)
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Upload successful but indexing failed: {str(e)}"
        )

